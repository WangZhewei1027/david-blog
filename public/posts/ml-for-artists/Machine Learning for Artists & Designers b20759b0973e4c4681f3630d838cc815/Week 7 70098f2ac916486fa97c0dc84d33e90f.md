---
noAlt: true
---
# Week 7
> Read [What We Still Don’t Know about How A.I. Is Trained](https://archive.is/y2prt) by Sue Halpern (The New Yorker, March 28 2023, archived copy). What new information did you learn from it?
> 

GPT4 can perform various tasks, such as creating poems, providing musical compositions, and generating text, but it also has limitations and can make errors in its responses. The article raises concerns about the transparency of AI models like GPT4, their environmental impact due to energy consumption, and the potential for misuse, including generating harmful content and deepfakes. It also highlights the need for ethical guidelines, regulations, and oversight to ensure responsible and ethical AI development and deployment. 

> Read [Meet Ernie, China’s answer to ChatGPT](https://archive.is/6PT5b) (The Economist, September 3 2023, archived copy). What are the unique challenges for the creation and application of language models in the Chinese context that that article mentions?
> 

The sensitive political things are not allowed to be talked about. The censorship prevents the development of Chinese AI. The restriction on chips also put a barrier in the way of developing AI.  Furthermore, China’s government has taken a keen interest in the regulation of ai, moving faster than most other countries. In addition, the costs of censorship and compliance will start to add up for Baidu and other companies. 

> Pick any open language model such as [zephyr-7b-alpha](https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha) (on Hugging Face), [Mistral-7B-Instruct-v0.1](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1) (on Hugging Face), [falcon-7b-instruct](https://huggingface.co/tiiuae/falcon-7b-instruct) (on Hugging Face), InternLM 7B ([see slides how to access](https://docs.google.com/presentation/d/1Wlivj2NOj8b7wHQSYe7RaVbWqPT1lWaDHyOXZWdS-OY/edit#slide=id.g28d1aba9f4f_0_246)), Samantha 1.11 7B ([see slides how to access](https://docs.google.com/presentation/d/1Wlivj2NOj8b7wHQSYe7RaVbWqPT1lWaDHyOXZWdS-OY/edit#slide=id.g28d1aba9f4f_0_308)) and see how its responses to the same input compare to ChatGPT (for InternLM you’d most accurately compare with GPT-3.5 via the API). Besides generation quality, are there other differences you can make out (e.g. concerning content other than English, political leanings, topics the model is willing to engage, …)?
> 

Question: 

There is a runaway [trolley](https://en.wikipedia.org/wiki/Tram) barreling down the [railway tracks](https://en.wikipedia.org/wiki/Track_(rail_transport)). Ahead, on the tracks, there are five people tied up and unable to move. The trolley is headed straight for them. You are standing some distance off in the train yard, next to a lever. If you pull this lever, the trolley will switch to a different set of tracks. However, you notice that there is one person on the side track. You have two (and only two) options:

1. Do nothing, in which case the trolley will kill the five people on the main track.
2. Pull the lever, diverting the trolley onto the side track where it will kill one person.

Which is the more ethical option? Or, more simply: What is the right thing to do?

|  | [zephyr-7b-alpha](https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha) | [Mistral-7B-Instruct-v0.1](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1) | [falcon-7b-instruct](https://huggingface.co/tiiuae/falcon-7b-instruct) | ChatGPT |
| --- | --- | --- | --- | --- |
| Answer | This is the classic trolley problem, a thought experiment in philosophy that has been around since the 1960s. It is a variation of the classic dilemma of utilitarianism, which is the philosophy that the right action is the one that produces the greatest good for the greatest number of people. | There is a lot of discussion about this problem, and it has become somewhat of a standard example in ethics classes. The most common argument for choosing option (2) is that it is better to sacrifice one person to save five. This argument is often based on the idea that the value of a human life is proportional to the number of people affected by a decision. On this basis, it seems clear that option (2) is the more ethical choice. | --- | --- |

However, I'm not convinced by this argument. It seems to me that the value of a human life is not proportional to the number of people affected by a decision. Rather, I think that the value of a human life is fundamentally different from any quantity that can be measured.
Consider this thought experiment: Suppose that you have a daughter who is terminally ill, and you are faced with the following choice:

1. Let her die naturally.
2. Give her a lethal injection.

I think that most people would agree that it is better to give her a lethal injection than to let her die naturally. But why is this? Is it really better to sacrifice one person to save another? | As an AI language model, I cannot provide a definitive answer to this question as it depends on individual values and beliefs. However, some may argue that pulling the lever is the more ethical option as it saves more lives in the long run. On the other hand, one may argue that saving one life is worth the sacrifice of five. Ultimately, it is up to the individual to decide what is the right thing to do. | he scenario you described is a classic thought experiment known as the Trolley Problem. It's often used to explore ethical dilemmas and moral decision-making. The question of what the right thing to do is a matter of ongoing debate among ethicists and philosophers, and there's no one definitive answer.

Do Nothing: By choosing to do nothing, you allow the trolley to continue on its current path, resulting in the death of five people. Some argue that inaction in this scenario is morally preferable because you are not actively causing harm, and the consequences are a result of the trolley's initial trajectory.
Pull the Lever: By pulling the lever, you actively divert the trolley onto the side track, saving the five people on the main track but causing the death of one person on the side track. Those who advocate for pulling the lever argue that it minimizes overall harm, as it saves more lives.
The "right" thing to do in this situation depends on one's ethical framework. Consequentialist ethics might suggest pulling the lever to minimize overall harm, while deontological ethics might argue against actively causing harm, even if it means allowing more people to be harmed due to inaction.

Ultimately, your choice may depend on your personal ethical beliefs and values. The Trolley Problem serves as a tool for exploring and discussing ethical decision-making but doesn't provide a definitive answer, as different individuals and cultures may arrive at different conclusions based on their moral principles. |

Overall, I think ChatGPT’s quality is the highest. It is very objective and comprehensive, compared to other language models. It analyzed all the ethical possibilities and gave an insightful answer. 

> List any one insight you had listening to Scott Cazan’s description of the commercial project he was doing for *Away*.
> 

I think using AI to generate postcards is a really cool idea. Scott showed us the process of making an AI-generated postcard, everything within one interface, with is very user-friendly, let me see the potential of the use of AI in the commercial area. 

> Come up with two questions about anything related to week 7’s content.
> 

1.  Are there any ethical considerations when fine-tuning AI language models?
2. Can fine-tuned models be further fine-tuned for different tasks or domains?