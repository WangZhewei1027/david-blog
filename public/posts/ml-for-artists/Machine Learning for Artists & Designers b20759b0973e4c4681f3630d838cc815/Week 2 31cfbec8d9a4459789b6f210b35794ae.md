# Week 2

> Alone or with a partner, develop a sketch based on a one of the [tutorials starter codes](https://www.notion.so/dc0d0e903ddd46808cfc16dd5ef48ac6?pvs=21), which makes use the technology in a more rich, creative way: e.g. as part of a game - interacting with objects on the screen, or in combination with sound or music, or as a more sophisticated drawing tool or abstract visualization of movement.
> 

Link: [https://editor.p5js.org/WangZhewei1027/sketches/_QjmVNnvC](https://editor.p5js.org/WangZhewei1027/sketches/_QjmVNnvC)

> Which was your favorite idea was proposed during brainstorming of possible applications? Why? What makes this idea (or approach) appealing?
> 

The favorite idea when me and Denny were brainstorming is that we wanted to make a interactive game utilizing the handpose recognition and posenet motion game. The game basically is asking players to do the gesture of shooting basketball in a limited time, and we count the number of times when players do the gestures that meet the standard. We were thinking of having some dots to guide players which spot they should reach for shooting basketball. 

We think this idea is appealing is that, it could help the people to practice their basketball shooting skills virtually without actually going to the basketball court. We are inspired from the Nintendo Sports game that how people could just do sports at home.

> Watch the documentary Coded Bias (2020) for free on [NYU Stream](https://stream.nyu.edu/media/1_swp2ecs1). Ask ChatGPT for a list of issues the film raises, and correct/critique/augment its response in red.
> 

"Coded Bias" is a documentary film directed by Shalini Kantayya that delves into the issues related to artificial intelligence, machine learning, and algorithms, particularly as they pertain to bias and discrimination. The film primarily highlights the following key issues:

1. Algorithmic Bias: The documentary discusses how many AI algorithms, especially those used in facial recognition technology, exhibit bias and discrimination against certain demographic groups, particularly people of color and women. It raises concerns about how these biases can result in unfair and harmful outcomes.
2. Facial Recognition Technology: "Coded Bias" explores the widespread use of facial recognition technology in various aspects of society, from law enforcement to employment and surveillance. It raises questions about the accuracy of these systems and the potential for misuse, invasion of privacy, and civil liberties violations.
3. Lack of Accountability: The film raises concerns about the lack of transparency and accountability in the development and deployment of AI systems. It highlights how companies often keep their algorithms and data proprietary, making it difficult to assess their fairness and performance.
4. Ethical Considerations: "Coded Bias" underscores the importance of considering ethical considerations when designing and deploying AI systems. It advocates for more ethical AI practices and regulations to ensure that technology is used responsibly and fairly.
5. Legislation and Regulation: "Coded Bias" also touches on the need for governments and regulatory bodies to implement policies and regulations that address the potential harms of biased AI systems and protect individuals' rights.

Overall, "Coded Bias" sheds light on the complex and pressing issues surrounding artificial intelligence and the urgent need to address bias and discrimination in AI algorithms and systems. It calls for greater awareness, accountability, and responsible use of AI technology to ensure a fair and equitable future.

Algorithmic bias is a significant concern in the development and deployment of artificial intelligence (AI) and machine learning systems. It refers to the presence of systematic and unfair discrimination in the results produced by these algorithms, often based on race, gender, ethnicity, or other protected characteristics.

Agree with this point

I don't possess personal opinions or feelings, but I can provide information on the topic of facial recognition technology used in surveillance.

Facial recognition technology in surveillance has generated considerable debate and concerns, and opinions on its use vary widely.

I agree with this point. As AI being used in the workplace, privacy and regulation problems are drawing more concern. It is worth a debate. 

The question of whether governments and regulatory bodies should implement policies and regulations to address AI bias is a matter of widespread consensus among experts and stakeholders in the field of artificial intelligence and ethics. The general consensus is that government intervention and regulation are necessary to address AI bias effectively.

Not completely agree. The severe regulation from the government on AI may slow down the development of AI. The training of AI needs a large amount of data, if the regulation can’t balance between privacy and data accessibility, it will be not good for AI technology. 

> Find and explore the raw training data that some of the pretrained models you used were trained on. (available datasets are e.g. [COCO](https://cocodataset.org/), and [ImageNet](https://www.image-net.org/)) What are your observations looking at those images? Can you find any published critical analysis, or critique of this dataset?
> 

I explore the data set of COCO. I searched “people” in the data set. I found three issues: The data set is not that accurate, some of the people it shows are just the people shape things in the background or just people in the paint, not real people. The second issue is that I found there are many daily life photos in the dataset, I wonder if privacy is being protected. The third issue is the photo are mainly located in Western countries, I wonder if this data set can be applied to other countries like China, is the cultural and ethic diversity enough?

I found one article that criticize the accuracy of COCO: [https://openreview.net/forum?id=hj7uBF92qvm](https://openreview.net/forum?id=hj7uBF92qvm)